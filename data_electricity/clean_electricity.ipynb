{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646ae786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f445d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in the dataset\n",
    "df_weather, df_load = pd.read_csv('raw/weather_info_spain.csv'), pd.read_csv('raw/electricity_dataset_spain.csv')\n",
    "df_weather['dt_iso'] = pd.to_datetime(df_weather['dt_iso']).apply(lambda x: pd.Timestamp(x).tz_localize(None))\n",
    "df_load['time'] = pd.to_datetime(df_load['time']).apply(lambda x: pd.Timestamp(x).tz_localize(None))\n",
    "df_load.rename(columns={'time':'dt_iso','price day ahead': 'price_forecast', 'price actual': 'price_actual', 'total load forecast': 'load_forecast', 'total load actual': 'load_actual'},inplace=True)\n",
    "\n",
    "df_weather = df_weather.groupby(['dt_iso']).agg({'temp':['min','median','mean','max'], 'humidity':['min','median','mean','max']})\n",
    "df_weather.columns = [f'{x[0]}_{x[1]}' for x in df_weather.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bf754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect the hf block\n",
    "df_hf = pd.merge(df_weather, df_load[['dt_iso','price_forecast','price_actual']],on='dt_iso',how='inner')\n",
    "## shift price_baseline by one-day since that's when it becomes available; shift weather by one hour\n",
    "df_hf['price_forecast'] = df_hf['price_forecast'].shift(-24)\n",
    "for col in ['temp','humidity']:\n",
    "    for ops in ['min','median','mean','max']:\n",
    "        df_hf[f'{col}_{ops}'] = df_hf[f'{col}_{ops}'].shift(-1)\n",
    "## take logarithm for price\n",
    "df_hf['price_forecast'] = np.log(df_hf['price_forecast']+1e-6)\n",
    "df_hf['price_actual'] = np.log(df_hf['price_actual']+1e-6)\n",
    "## add +1hr to the timestamp, so that it corresponds to the end\n",
    "df_hf['dt_iso'] = df_hf['dt_iso'].apply(lambda x: x + pd.Timedelta(hours=+1))\n",
    "df_hf = df_hf.set_index('dt_iso').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352159a",
   "metadata": {},
   "source": [
    "**check for missing timestamps for the high-frequency data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b19572d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_hf_list = [df_hf.index.min() + datetime.timedelta(hours=x) for x in range(int(24*((df_hf.index.max()-df_hf.index.min()).days+1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b5c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing stamps for hf: {Timestamp('2016-03-27 03:00:00'), Timestamp('2017-03-26 03:00:00'), Timestamp('2018-03-25 03:00:00'), Timestamp('2015-03-29 03:00:00')}\n"
     ]
    }
   ],
   "source": [
    "hf_missing_stamps = set(timestamp_hf_list) - set(df_hf.index)\n",
    "print(f'missing stamps for hf: {hf_missing_stamps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0824b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hf_missing = pd.DataFrame(index = list(hf_missing_stamps), columns=df_hf.columns)\n",
    "df_hf = pd.concat([df_hf, df_hf_missing]).sort_index().ffill()\n",
    "df_hf.index.name = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d925dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated stamps for hf: DatetimeIndex(['2015-10-25 03:00:00', '2016-10-30 03:00:00',\n",
      "               '2017-10-29 03:00:00', '2018-10-28 03:00:00'],\n",
      "              dtype='datetime64[ns]', name='timestamp', freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(f'duplicated stamps for hf: {df_hf.index[df_hf.index.duplicated()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c94b3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hf = df_hf.loc[~df_hf.index.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8e9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect the lf block\n",
    "df_lf = df_load[['dt_iso','load_forecast','load_actual']].copy()\n",
    "## shift load_forecast by 24 hr\n",
    "df_lf['load_forecast'] = df_lf['load_forecast'].shift(-24)\n",
    "## create lf timestamp\n",
    "df_lf['dt_6H'] = df_lf['dt_iso'].apply(lambda x: (x + pd.Timedelta(hours=+1)).ceil(\"6H\"))\n",
    "df_lf = df_lf.groupby(['dt_6H']).agg({'load_forecast':'sum','load_actual':'sum'})\n",
    "## logarithm of load\n",
    "df_lf['load_forecast'] = np.log(df_lf['load_forecast']+1).replace(to_replace=0, method='ffill')\n",
    "df_lf['load_actual'] = np.log(df_lf['load_actual']+1).replace(to_replace=0, method='ffill')\n",
    "df_lf.index.name = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d9e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_lf_list = set([x.ceil(\"6H\") for x in timestamp_hf_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7696aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing stamps for lf: set()\n"
     ]
    }
   ],
   "source": [
    "lf_missing_stamps = set(timestamp_lf_list) - set(df_lf.index)\n",
    "print(f'missing stamps for lf: {lf_missing_stamps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced66ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated stamps for lf: DatetimeIndex([], dtype='datetime64[ns]', name='timestamp', freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(f'duplicated stamps for lf: {df_lf.index[df_lf.index.duplicated()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bce80a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lf = df_lf.loc[df_lf.index <= df_hf.index.max()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a19758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'electricity.xlsx') as writer:\n",
    "    df_hf.to_excel(writer,sheet_name='x',index=True)\n",
    "    df_lf.drop(columns=['load_forecast']).to_excel(writer,sheet_name='y',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19701400-d8d0-4980-8c34-294a7742d7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
